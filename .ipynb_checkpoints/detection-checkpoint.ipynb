{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a86c9938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: silence_tensorflow in c:\\users\\ananya saha\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: support-developer in c:\\users\\ananya saha\\anaconda3\\lib\\site-packages (from silence_tensorflow) (1.0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ananya saha\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install silence_tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fe009c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To avoid tensorflow warnings\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "# To avoid other python wsrnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f64600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "\u001b[1m\u001b[34mAll libraries imported succesfully\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "import ipywidgets\n",
    "from IPython.display import display,clear_output\n",
    "\n",
    "print(colored('All libraries imported succesfully', 'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04347e90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m colors_dark \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#0A2342\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#ff0000\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#f2f2f2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1d84b5\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#f4edea\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#c5d8d1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#eef1fb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mpalplot(colors_dark)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "colors_dark = [\"#0A2342\", '#ff0000', '#f2f2f2', \"#1d84b5\" , '#f4edea', '#c5d8d1', '#eef1fb']\n",
    "\n",
    "sns.palplot(colors_dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf42ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of main Dataset\n",
    "base_dir = 'C:\\\\Users\\\\Ananya saha\\\\Downloads\\\\BrainTumor_detection_CNN\\\\archive3\\\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6596892",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Ananya saha\\\\Downloads\\\\detection_project1\\\\archive3\\\\Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Loop over folders to extract class_names\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classes \u001b[38;5;241m=\u001b[39m [class_name \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m      3\u001b[0m classes\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Ananya saha\\\\Downloads\\\\detection_project1\\\\archive3\\\\Data'"
     ]
    }
   ],
   "source": [
    "# Loop over folders to extract class_names\n",
    "classes = [class_name for class_name in os.listdir(base_dir)]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc8b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A loop to iterate below codes for each class\n",
    "for class_name in classes :\n",
    "    # To create a plot with 1 row and 6 column\n",
    "    fig, ax = plt.subplots(1, 6, figsize=(15, 3))\n",
    "    # Define a variable for each class_name's path by joining base_directory and each class_name\n",
    "    class_path = os.path.join(base_dir, class_name)\n",
    "    # Files is a list of all image names in each folder (class)\n",
    "    files = os.listdir(class_path)\n",
    "    # Choose 6 random image from each class to show in plot\n",
    "    random_images = random.choices(files, k=6)\n",
    "    # A loop to iterate in each 6 random images\n",
    "    for i in range(6) :\n",
    "        # print class_name as suptitle for each class\n",
    "        plt.suptitle(class_name, fontsize=20, fontweight='bold')\n",
    "        # variable img is path of image, by joining class_path and image file name\n",
    "        img = os.path.join(class_path ,random_images[i])\n",
    "       # load image in img variable using keras.utils.load_img(image_path) \n",
    "        img = keras.utils.load_img(img)\n",
    "        # Plot image\n",
    "        ax[i].imshow(img)\n",
    "        # Turn axis off\n",
    "        ax[i].axis('off')\n",
    "    # Make plots to become nearer to each other\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count is a list to store number of images for each class.\n",
    "counts = [] \n",
    "# Loop over classes to iterate below code for each class\n",
    "for class_name in classes :\n",
    "    # Define class path by joining base_directory and class_name\n",
    "    class_path = os.path.join(base_dir, class_name)\n",
    "    # Add number of files in each class to count list\n",
    "    counts.append(len(os.listdir(class_path)))\n",
    "\n",
    "# Define plot size\n",
    "plt.figure(figsize=(13, 4))\n",
    "# Using seaborn to plot a barplot for each class\n",
    "ax = sns.barplot(y=classes, x=counts)\n",
    "# Set X-axis range and ticks\n",
    "ax.set_xticks(range(0, 950, 100))\n",
    "# Annotate each bar with the count\n",
    "for i, p in enumerate(ax.patches):\n",
    "    width = p.get_width()\n",
    "    ax.text(width + 5, p.get_y() + p.get_height()/2., \n",
    "            '{}'.format(counts[i]),\n",
    "            va=\"center\", fontsize=10)\n",
    "# Set plot title\n",
    "plt.title('Number of images per class', fontsize=25, fontweight='bold')\n",
    "# Set Y-axis label\n",
    "plt.ylabel('Classes', fontsize=15)\n",
    "# Set X-axis label\n",
    "plt.xlabel('Number of samples', fontsize=15)\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sumation of all values in count list as all image counts.\n",
    "sum_count_before = sum(counts)\n",
    "print(colored(f'Number of all images is : {sum_count_before}', 'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d76d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our data to tensorflow dataset by keras.utils.image_dataset_from_directory\n",
    "train_full = keras.utils.image_dataset_from_directory(\n",
    "    directory=base_dir,        # Path of base directory\n",
    "    labels='inferred',         # to generate labels from the directory structure\n",
    "    label_mode='categorical',  # type of labels\n",
    "    class_names=classes,       # list of class_names\n",
    "    shuffle=True,              # To shuffle dataset\n",
    "    seed=42,                   # Optional random seed for shuffling and transformations\n",
    "    batch_size=32,             # Define batch size\n",
    "    image_size=(224, 224)      # Size to resize images to after they are read from disk\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ce2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset again after creation\n",
    "train_full = train_full.shuffle(1024).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d01c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Number of all batches in dataset\n",
    "num_of_full_train_batches = len(list(train_full))\n",
    "print(colored(f'Number of batches in train_full : {num_of_full_train_batches}', 'black', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf88b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variable to store number of batches for train dataset\n",
    "num_train_batches = int(num_of_full_train_batches * 0.80)\n",
    "# Define variable to store number of batches for validation and test dataset\n",
    "num_valid_test_batches = num_of_full_train_batches - num_train_batches\n",
    "\n",
    "\n",
    "# Print the TARGET : number of batches for train, validation and test dataset to each\n",
    "print(colored(' Target : ', 'green', attrs=['bold']))\n",
    "print('-'*35)\n",
    "print(colored(f'Number of  Train  batches : {num_train_batches}', 'blue', attrs=['bold']))\n",
    "print(colored(f'Number of Validation batches : {num_valid_test_batches//2}', 'blue', attrs=['bold']))\n",
    "print(colored(f'Number of Test batches : {num_valid_test_batches//2}', 'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc455d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle dataset\n",
    "train_full = train_full.shuffle(buffer_size=3)\n",
    "\n",
    "# Apply above settings to main dataset to split to train, validation and test dataset\n",
    "train_ds = train_full.take(num_train_batches)\n",
    "remain_ds = train_full.skip(num_train_batches)\n",
    "valid_ds = remain_ds.take(num_valid_test_batches//2) \n",
    "test_ds = remain_ds.skip(num_valid_test_batches//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c80202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of batches in train, validation and test dataset after split them\n",
    "print(colored(f'Number of train batches : {len(list(train_ds))}', 'green', attrs=['bold']))\n",
    "print(colored(f'Number of valid batches : {len(list(valid_ds))}', 'green', attrs=['bold']))\n",
    "print(colored(f'Number of test  batches : {len(list(test_ds))}', 'green', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ResNet50V2 from keras.application as pre trained model with imagenet weight\n",
    "pre_trained_model = keras.applications.ResNet50V2(\n",
    "    weights='imagenet', classes=4, input_shape=(224, 224, 3), include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers, except last layer\n",
    "# The goal is to train just last layer of pre trained model\n",
    "\n",
    "pre_trained_model.trainable = True               # Whole model is trainable\n",
    "set_trainable = False                            # Set a flag to False\n",
    "\n",
    "for layer in pre_trained_model.layers :          # A loop over model's layers\n",
    "    if layer.name == 'conv5_block1_preact_bn' :  # Define target layer's name (with if condition)\n",
    "        set_trainable = True                     # Change flag value to True\n",
    "    if set_trainable :                           # A condition for True flag\n",
    "        layer.trainable = True                   # Set layer trainablity to True\n",
    "    else :                                       # else condition\n",
    "        layer.trainable = False                  # For layers befor our target layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = keras.models.Sequential()\n",
    "model.add(pre_trained_model)                           # At first add our pre-trained model\n",
    "model.add(keras.layers.Dropout(0.5))                   # Use a Dropout layer to avoid over-fitting\n",
    "model.add(keras.layers.GlobalAveragePooling2D())       # Apply GlobalAveragePooling2D\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1024, activation='relu')) # Add a Dense layer with 1024 neuron with activation='relu'\n",
    "model.add(keras.layers.Dropout(0.5))                   # Use a Dropout layer to avoid over-fitting\n",
    "model.add(keras.layers.Dense(512, activation='relu'))  # Add a Dense layer with 512 neuron with activation='relu'\n",
    "model.add(keras.layers.Dropout(0.5))                   # Use a Dropout layer to avoid over-fitting\n",
    "model.add(keras.layers.Dense(4, activation='softmax')) # Add a Dense layer with number fo classes neuron as output with activation='softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3094b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2570bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model CheckPoint Call-Back, to save best model parameters as a .keras file\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('MyModel.keras', save_best_only=True) \n",
    "\n",
    "# Early Stoping Call-Backc to stop trainig process after 'patience' epochs if the metric doesn't grow\n",
    "earlystop_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# ReduceLROnPlateau Call-Back to decrease learning-rate base on 'monitor' parameter after 'patience' epochs with a 'factor' is doesn't improve\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0430c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model by .fit function\n",
    "history = model.fit(\n",
    "    train_ds,                                          # Dataset to train model\n",
    "    epochs=1,                                        # Number of epochs to train\n",
    "    validation_data=valid_ds,                          # Validation dataset\n",
    "    #callbacks=[checkpoint_cb, earlystop_cb, reduce_lr] # List of call backs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863484f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"mymodel1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd88c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resutl of training to a DataFrame\n",
    "result_df = pd.DataFrame(history.history)\n",
    "# Show 5 tails of dataframe\n",
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fe349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a X variable to store range of epochs\n",
    "x = np.arange(len(result_df))\n",
    "\n",
    "# Create a plot with 3 row and 1 col with size of (15, 12)\n",
    "fig, ax = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# AX0 : Loss\n",
    "ax[0].plot(x, result_df.loss, label='loss', linewidth=3)                          \n",
    "ax[0].plot(x, result_df.val_loss, label='val_loss', linewidth=2, ls='-.', c='r')\n",
    "ax[0].set_title('Loss', fontsize=20)\n",
    "ax[0].set_xticks(np.arange(0, len(x), 2))\n",
    "ax[0].legend()\n",
    "\n",
    "#  AX1 : Loss\n",
    "ax[1].plot(x, result_df.accuracy, label='accuracy', linewidth=2)\n",
    "ax[1].plot(x, result_df.val_accuracy, label='val_accuracy', linewidth=2, ls='-.', c='r')\n",
    "ax[1].set_title('Accuracy', fontsize=20)\n",
    "ax[1].set_xticks(np.arange(0, len(x), 2))\n",
    "ax[1].legend()\n",
    "\n",
    "#  AX2 : Loss\n",
    "ax[2].plot(x, label='learning_rate', linewidth=2, marker='o')\n",
    "ax[2].set_title('learning_rate', fontsize=20)\n",
    "ax[2].set_xlabel('epochs')\n",
    "ax[2].set_xticks(np.arange(0, len(x), 2))\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b11246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ef4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model('MyModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e7b29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
